{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd5150a-d33e-435b-ac47-3fdf15fb05c2",
   "metadata": {},
   "source": [
    "# Quality Assurance <a href=\"https://colab.research.google.com/github/mostly-ai/mostlyai/blob/main/docs/tutorials/quality-assurance/quality-assurance.ipynb\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Open%20in-Colab-blue?logo=google-colab\" alt=\"Run on Colab\"></a>\n",
    "\n",
    "In this tutorial we will leverage `mostlyai-qa`, the open-source Python toolkit to assess Synthetic Data quality. See also https://mostly-ai.github.io/mostlyai-qa/ for more info on that toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311dfb2",
   "metadata": {},
   "outputs": [],
   "source": "%pip install -U mostlyai-qa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3bd75-3d32-44e2-87d3-b9895753b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import pandas as pd\n",
    "from mostlyai import qa\n",
    "\n",
    "# initialize logging to stdout\n",
    "qa.init_logging()\n",
    "\n",
    "# print version\n",
    "print(f\"loaded mostlyai-qa {qa.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08145f83-a985-4f4b-a02f-6f3ed3dbe6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"https://github.com/mostly-ai/paper-fidelity-accuracy/raw/refs/heads/main/2024-12/data\"\n",
    "trn = pd.read_csv(f\"{repo}/adult_trn.csv.gz\")\n",
    "hol = pd.read_csv(f\"{repo}/adult_hol.csv.gz\")\n",
    "syn = pd.read_csv(f\"{repo}/adult_mostlyai.csv.gz\")\n",
    "print(f\"fetched training data with {trn.shape[0]:,} records and {trn.shape[1]} attributes\")\n",
    "print(f\"fetched holdout data with {hol.shape[0]:,} records and {hol.shape[1]} attributes\")\n",
    "print(f\"fetched synthetic data with {syn.shape[0]:,} records and {syn.shape[1]} attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce2c48-89e8-4f87-bcfe-97be95e25212",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d955e83-d15d-4a74-a85a-55c60c248d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e7026-494d-484d-b935-e366a4d695f4",
   "metadata": {},
   "source": [
    "## Generate HTML Report with Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c056183-1d3c-40a2-b528-90f058ce1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 1-2 minutes\n",
    "report_path, metrics = qa.report(\n",
    "    syn_tgt_data=syn,\n",
    "    trn_tgt_data=trn,\n",
    "    hol_tgt_data=hol,\n",
    "    max_sample_size_embeddings=1_000,  # set limit to speed up demo; remove limit for best measures\n",
    ")\n",
    "\n",
    "# pretty print metrics\n",
    "print(metrics.model_dump_json(indent=4))\n",
    "\n",
    "# open up HTML report in new browser window\n",
    "webbrowser.open(f\"file://{report_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23776f87-1bf3-4145-9942-38386c77a923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
